{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial\n",
    "### Quick start\n",
    "Create pipeline task with task decorators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"..\")\n",
    "\n",
    "import dagpipe\n",
    "\n",
    "\n",
    "@dagpipe.task()\n",
    "def run_a(param):\n",
    "    return f\"Output of A with {param}\"\n",
    "\n",
    "@dagpipe.task()\n",
    "def run_b(a):\n",
    "    return f\"Output of B with {a}\"\n",
    "\n",
    "@dagpipe.task()\n",
    "def run_c(b):\n",
    "    return f\"Output of C with {b}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = run_a(param=\"Initial input for A\")\n",
    "b = run_b(a)\n",
    "c = run_c(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_pipeline = dagpipe.Pipeline(\n",
    "  inputs=a,\n",
    "  outputs=c\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize:  \n",
    "\n",
    "\n",
    "*Note: This step would only works if you will have properly installed Graphviz on your computer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dagpipe.visualize(simple_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionality overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task\n",
    "Two types of tasks are supported:\n",
    "1. Function task defined with `task` decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dagpipe.task()\n",
    "def A(param):\n",
    "    return f\"Output of A with {param}\"\n",
    "\n",
    "@dagpipe.task()\n",
    "def B(a):\n",
    "    return f\"Output of B with {a}\"\n",
    "\n",
    "@dagpipe.task()\n",
    "def C(b):\n",
    "    return f\"Output of C with {b}\"\n",
    "\n",
    "@dagpipe.task()\n",
    "def D(a, c):\n",
    "    return f\"Output of D with {a} and {c}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Method tasks defined with `method_task` decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleClass:\n",
    "    @dagpipe.method_task()\n",
    "    def E(self, d):\n",
    "        return f\"Output of E with {d}\"\n",
    "\n",
    "    @dagpipe.method_task()\n",
    "    def F(self, e):\n",
    "        return f\"Output of F with {e}\"\n",
    "\n",
    "    @dagpipe.method_task()\n",
    "    def G(self, inp):\n",
    "        return f\"Output of G with {inp}\"\n",
    "\n",
    "    @dagpipe.method_task()\n",
    "    def __call__(self, inp):\n",
    "        return f\"Output from Exampleclass with {inp}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks flow is defined in very intuitive way (like normal functions execution).  \n",
    "Note that:\n",
    "1. You can mix in single pipeline tasks with methods tasks.\n",
    "2. You can put more tasks to single task   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ExampleClass()\n",
    "\n",
    "a = A(param=\"Initial input for A\")\n",
    "b = B(a)\n",
    "c = C(b)\n",
    "d = D(a, c)\n",
    "e = example.E(d)\n",
    "f = example.F(e)\n",
    "g = example.G(c)\n",
    "ec = example(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline\n",
    "To define pipeline simply pass input and outputs to Pipeline.  \n",
    "You can define as many output as you want, but only one input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = dagpipe.Pipeline(inputs=a, outputs=[f, ec])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the same pipeline with different parameters. Your result would be a list with values for each defined output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline.run()\n",
    "print(result)\n",
    "\n",
    "new_result = pipeline.run(param=\"## New input for A ##\")\n",
    "print(new_result)\n",
    "\n",
    "new_result2 = pipeline.run(param=\"@@ New input for A @@\")\n",
    "print(new_result2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But be aware, that when you run it again without parameters it will use last defined parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline.run()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`visualize` function create `matplotlib` plot that you can customize.  \n",
    "\n",
    "Alternatively you can save visualization fo file instead of plotting, by specifying parameter to_file: `dagpipe.visualize(pipeline, to_file=\"path/to/file\")`\n",
    "\n",
    "\n",
    "Tasks are named with theirs functions names. Method tasks like `ClassName.function_name`, but there is one special case: `__call__` method is named only with class name.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "dagpipe.visualize(pipeline)\n",
    "plt.title(\"Example pipeline\")\n",
    "plt.gcf().set_size_inches(4, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.tasks[0].name = \"AAA\"\n",
    "dagpipe.visualize(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "class Foo2:\n",
    "    def __call__(self, inp):\n",
    "        return inp\n",
    "    \n",
    "    def x(self, inp):\n",
    "        return inp\n",
    "    \n",
    "def self_evaluated(self):\n",
    "    return self\n",
    "\n",
    "\n",
    "\"(self\" in str(inspect.signature(Foo2.x))\n",
    "\"(self\" in str(inspect.signature(self_evaluated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output split\n",
    "You have to specify `outputs_num` in Task decorator if you want to return more than one output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "@dagpipe.task()\n",
    "def do_nothing(inp):\n",
    "    return inp\n",
    "\n",
    "@dagpipe.task(outputs_num=2)\n",
    "def split(inp):\n",
    "    print(\"runnin\")\n",
    "    return inp[0], inp[1]\n",
    "\n",
    "@dagpipe.task()\n",
    "def duplicate(inp):\n",
    "    return inp*2\n",
    "\n",
    "@dagpipe.task()\n",
    "def concat(inp1, inp2):\n",
    "    return inp1 + inp2\n",
    "\n",
    "x1 = do_nothing(Any)\n",
    "x2, x3 = split(x1)\n",
    "x5 = duplicate(x3)\n",
    "x6 = concat(x2, x5)\n",
    "\n",
    "p = dagpipe.Pipeline(x1, [x6])\n",
    "\n",
    "dagpipe.visualize(p)\n",
    "p.run([\"*first element*\", \"@second element@\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set name\n",
    "you can set name during flow definition with `set_name` Task method. If you need to name more than one task, just pass list of names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = do_nothing(Any).set_name(\"Input Node\")\n",
    "x2, x3 = split(x1).set_name([\"Split - left side\", \"Split - right side\"])\n",
    "x5 = duplicate(x3)\n",
    "x6 = concat(x2, x5)\n",
    "\n",
    "p = dagpipe.Pipeline(x1, [x6])\n",
    "\n",
    "dagpipe.visualize(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential pipe\n",
    "if your flow is really straightforward you can define it as `sequence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = dagpipe.Pipeline.sequential([\n",
    "    do_nothing,\n",
    "    duplicate,\n",
    "    duplicate,\n",
    "])\n",
    "dagpipe.visualize(p)\n",
    "p.run(\"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### conditional_stops\n",
    "You can stop pipeline execution conditionally at any step if you specify `conditional_stops` argument in pipeline definition. It is a dict where key is `Task.name` and value is function that would take Task output and will convert it to boolean value. If True returned pipeline execution would be stopped and given task output returned with `StoppingTaskHolder` as second list element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_string(x):\n",
    "    return isinstance(x, str)\n",
    "\n",
    "p = dagpipe.Pipeline.sequential(\n",
    "    tasks_sequence=[do_nothing, duplicate, duplicate],\n",
    "    conditional_stops={\"do_nothing\": is_string}\n",
    ")\n",
    "\n",
    "print(\"noramlr run\", p.run(5))\n",
    "print(\"stopped run\", p.run(\"5\"))\n",
    "\n",
    "outputs = p.run(\"5\")\n",
    "if dagpipe.StoppingTaskHolder.in_(outputs):\n",
    "    print(\"wrong input format\")\n",
    "\n",
    "dagpipe.visualize(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StoppingTaskHolder\n",
    "you can easily filter out runs that stopped early with `StoppingTaskHolder.in_` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = p.run(\"5\")\n",
    "if dagpipe.StoppingTaskHolder.in_(outputs):\n",
    "    print(\"wrong input format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dig deeper \n",
    "`dagpipe.task` decorator change function behavior in a way that when it is called it saves base function with its arguments to `Task` object instead of calling it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dagpipe.task()\n",
    "def do_nothing(x):\n",
    "  return x\n",
    "\n",
    "x = 1\n",
    "print(f\"x type before foo processing - {type(x)}\")\n",
    "x = do_nothing(x)\n",
    "print(f\"x type after  foo processing - {type(x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check values that are stored by Task x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Stored function:\", x.func)\n",
    "print(\"Stored args: \\t\", x.args)\n",
    "print(\"Stored kwargs: \\t\", x.kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want run stored function, it is possible with `run` method, but normally `Pipeline` object would do it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task stores information about input arguments that that are provided to it, so when you put another Task as input to your task, it will have information about function that should be run before.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dagpipe.task()\n",
    "def foo2(x):\n",
    "  return x\n",
    "\n",
    "inp = 1\n",
    "x = do_nothing(inp)\n",
    "x2 = foo2(x)\n",
    "\n",
    "print(f\"input arg for x2 is '{x2.args[0]}' which type is {type(x2.args[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically tuple (*task*, *task argument*) is edge of directional computing graph. `dagpipe.Pipeline` collect information about all edges, and sort them in right execution order. After that you can run whole pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = dagpipe.Pipeline(input=x, outputs=[x2])\n",
    "pipeline.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
